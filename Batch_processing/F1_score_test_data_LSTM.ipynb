{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing function from a different ipny \n",
    "import pandas as pd\n",
    "import collections\n",
    "from keras.initializers import Constant\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import operator\n",
    "from itertools import product\n",
    "import sys\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from functools import reduce\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "pd.options.display.max_columns = 1000\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Activation, Input, BatchNormalization, MaxPooling1D, Bidirectional,LSTM\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPool1D, Flatten , Embedding, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "#https://www.amazon.com/Neural-Networks-Deep-Learning-Textbook/dp/3319944622/ref=cm_cr_arp_d_product_top?ie=UTF8\n",
    "#https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_NUM_WORDS = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>isspam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Confidential :Soma:, Ci@lis, :P:ntermin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>¢Â ÇªÁüÇÑ ¼³³¯ ÀÌº¥Æ® ÀÀ¸ðÇØ¼­ ºÎ¸ð´Ô²² ¼±¹°ÇÏ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_na_</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StOck 0ppurtunities - their sh0Oting</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>All your prescr[iption needs right here</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Subject  isspam\n",
       "0            Confidential :Soma:, Ci@lis, :P:ntermin       1\n",
       "1  ¢Â ÇªÁüÇÑ ¼³³¯ ÀÌº¥Æ® ÀÀ¸ðÇØ¼­ ºÎ¸ð´Ô²² ¼±¹°ÇÏ...       1\n",
       "2                                               _na_       1\n",
       "3               StOck 0ppurtunities - their sh0Oting       1\n",
       "6            All your prescr[iption needs right here       1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_data = pd.read_csv('subject_spam.csv', index_col=0, encoding='utf8', engine='python')\n",
    "keras_data.fillna(\"_na_\", inplace = True)\n",
    "keras_data = keras_data.drop(keras_data[keras_data.isspam == \"_na_\"].index)\n",
    "spammer = {'spam ': 1,'ham ': 0} \n",
    "keras_data.isspam = [spammer[item] for item in keras_data.isspam] \n",
    "spam_index = keras_data[keras_data.isspam ==1].index\n",
    "ham_index = keras_data[keras_data.isspam == 0].index\n",
    "new_index = np.concatenate((spam_index[:10000], ham_index[:9997]), axis=0)\n",
    "keras_data_new = keras_data.iloc[new_index]\n",
    "labels = keras_data_new.isspam\n",
    "keras_data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT = 0.2\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "Processing text dataset\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(os.path.join('glove.6B.100d.txt')) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "# second, prepare text samples and their labels\n",
    "print('Processing text dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15425 unique tokens.\n",
      "Shape of data tensor: (19997, 1000)\n",
      "Shape of label tensor: (19997, 2)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(keras_data_new.Subject)\n",
    "sequences = tokenizer.texts_to_sequences(keras_data_new.Subject)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-num_validation_samples]\n",
    "y_train = labels[:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = labels[-num_validation_samples:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing embedding matrix.\n",
      "Training model.\n"
     ]
    }
   ],
   "source": [
    "print('Preparing embedding matrix.')\n",
    "\n",
    "# prepare embedding matrix\n",
    "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "\n",
    "print('Training model.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>isspam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19223</th>\n",
       "      <td>RE: Daily Summary of Risk Data</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19224</th>\n",
       "      <td>Softwares CDS all software under 15$ and 99$!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19226</th>\n",
       "      <td>Hotel Room Bargains at up to 70% off!  Save in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19227</th>\n",
       "      <td>RE: Greeley Gas Company</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19228</th>\n",
       "      <td>Any Software just in under 15-99$, Xp-adobe etc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Subject  isspam\n",
       "19223                     RE: Daily Summary of Risk Data       0\n",
       "19224      Softwares CDS all software under 15$ and 99$!       1\n",
       "19226  Hotel Room Bargains at up to 70% off!  Save in...       1\n",
       "19227                            RE: Greeley Gas Company       0\n",
       "19228    Any Software just in under 15-99$, Xp-adobe etc       1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_data = pd.read_csv('subject_spam.csv', index_col=0, encoding='utf8', engine='python')\n",
    "keras_data.fillna(\"_na_\", inplace = True)\n",
    "keras_data = keras_data.drop(keras_data[keras_data.isspam == \"_na_\"].index)\n",
    "spammer = {'spam ': 1,'ham ': 0} \n",
    "keras_data.isspam = [spammer[item] for item in keras_data.isspam] \n",
    "spam_index = keras_data[keras_data.isspam ==1].index\n",
    "ham_index = keras_data[keras_data.isspam == 0].index\n",
    "new_index = np.concatenate((spam_index[10000:19000], ham_index[9997:19000]), axis=0)\n",
    "keras_data_test_set = keras_data.iloc[new_index]\n",
    "labels_test_set = keras_data_test_set.isspam\n",
    "keras_data_test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15425 unique tokens.\n",
      "Shape of data tensor: (17088, 1000)\n",
      "Shape of label tensor: (19997, 2)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(keras_data_new.Subject)\n",
    "sequences = tokenizer.texts_to_sequences(keras_data_test_set.Subject)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "#labels_test_set = to_categorical(np.asarray(labels_test_set))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "#labels_test_set = labels_test_set[indices]\n",
    "x_test = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_LSTM = pd.read_csv('embeddings_LSTM_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dl</th>\n",
       "      <th>fl1</th>\n",
       "      <th>fl2</th>\n",
       "      <th>fl3</th>\n",
       "      <th>kl</th>\n",
       "      <th>layer</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.928179</td>\n",
       "      <td>0.180042</td>\n",
       "      <td>0.924231</td>\n",
       "      <td>0.182697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.925866</td>\n",
       "      <td>0.178017</td>\n",
       "      <td>0.926732</td>\n",
       "      <td>0.188866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.920928</td>\n",
       "      <td>0.190786</td>\n",
       "      <td>0.925981</td>\n",
       "      <td>0.194389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.914677</td>\n",
       "      <td>0.205629</td>\n",
       "      <td>0.923231</td>\n",
       "      <td>0.196220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.911114</td>\n",
       "      <td>0.211151</td>\n",
       "      <td>0.919730</td>\n",
       "      <td>0.197624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.920240</td>\n",
       "      <td>0.193405</td>\n",
       "      <td>0.920480</td>\n",
       "      <td>0.198082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.922865</td>\n",
       "      <td>0.191926</td>\n",
       "      <td>0.923981</td>\n",
       "      <td>0.198908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.919740</td>\n",
       "      <td>0.190584</td>\n",
       "      <td>0.923731</td>\n",
       "      <td>0.199320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.920428</td>\n",
       "      <td>0.194369</td>\n",
       "      <td>0.916729</td>\n",
       "      <td>0.200601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.912677</td>\n",
       "      <td>0.216945</td>\n",
       "      <td>0.923731</td>\n",
       "      <td>0.200625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.916052</td>\n",
       "      <td>0.206061</td>\n",
       "      <td>0.920730</td>\n",
       "      <td>0.201580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.913802</td>\n",
       "      <td>0.214059</td>\n",
       "      <td>0.925731</td>\n",
       "      <td>0.201666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.902425</td>\n",
       "      <td>0.234574</td>\n",
       "      <td>0.921480</td>\n",
       "      <td>0.201901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.923928</td>\n",
       "      <td>0.184304</td>\n",
       "      <td>0.921980</td>\n",
       "      <td>0.202962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.917865</td>\n",
       "      <td>0.199268</td>\n",
       "      <td>0.916229</td>\n",
       "      <td>0.205678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.914739</td>\n",
       "      <td>0.208699</td>\n",
       "      <td>0.913728</td>\n",
       "      <td>0.208014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.893987</td>\n",
       "      <td>0.253523</td>\n",
       "      <td>0.919480</td>\n",
       "      <td>0.209666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.907801</td>\n",
       "      <td>0.223627</td>\n",
       "      <td>0.917229</td>\n",
       "      <td>0.211133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.903425</td>\n",
       "      <td>0.234117</td>\n",
       "      <td>0.916229</td>\n",
       "      <td>0.213399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.904676</td>\n",
       "      <td>0.230639</td>\n",
       "      <td>0.912978</td>\n",
       "      <td>0.215362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.912552</td>\n",
       "      <td>0.209694</td>\n",
       "      <td>0.912478</td>\n",
       "      <td>0.215649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.906113</td>\n",
       "      <td>0.225765</td>\n",
       "      <td>0.909977</td>\n",
       "      <td>0.218334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.909614</td>\n",
       "      <td>0.220658</td>\n",
       "      <td>0.916729</td>\n",
       "      <td>0.219749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.905801</td>\n",
       "      <td>0.230600</td>\n",
       "      <td>0.914479</td>\n",
       "      <td>0.220257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.902613</td>\n",
       "      <td>0.237722</td>\n",
       "      <td>0.912228</td>\n",
       "      <td>0.222930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.911426</td>\n",
       "      <td>0.211637</td>\n",
       "      <td>0.913228</td>\n",
       "      <td>0.223369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.902113</td>\n",
       "      <td>0.235470</td>\n",
       "      <td>0.912728</td>\n",
       "      <td>0.226381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.897862</td>\n",
       "      <td>0.249688</td>\n",
       "      <td>0.903476</td>\n",
       "      <td>0.235442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.811101</td>\n",
       "      <td>0.439903</td>\n",
       "      <td>0.846712</td>\n",
       "      <td>0.375535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.818477</td>\n",
       "      <td>0.424162</td>\n",
       "      <td>0.837959</td>\n",
       "      <td>0.377356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.819102</td>\n",
       "      <td>0.430787</td>\n",
       "      <td>0.842711</td>\n",
       "      <td>0.378661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.818415</td>\n",
       "      <td>0.442531</td>\n",
       "      <td>0.845711</td>\n",
       "      <td>0.380126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.815914</td>\n",
       "      <td>0.448350</td>\n",
       "      <td>0.844211</td>\n",
       "      <td>0.383301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.806538</td>\n",
       "      <td>0.448809</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.385470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.814289</td>\n",
       "      <td>0.454584</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.396841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.809226</td>\n",
       "      <td>0.447843</td>\n",
       "      <td>0.831208</td>\n",
       "      <td>0.401181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.802600</td>\n",
       "      <td>0.475585</td>\n",
       "      <td>0.837709</td>\n",
       "      <td>0.406585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dl  fl1  fl2  fl3  kl layer optimizer  train_acc  train_loss   val_acc  \\\n",
       "27   64   32    0    0   0   [1]     Nadam   0.928179    0.180042  0.924231   \n",
       "31  128   32    0    0   0   [1]     Nadam   0.925866    0.178017  0.926732   \n",
       "19   16   32    0    0   0   [1]     Nadam   0.920928    0.190786  0.925981   \n",
       "35   16   64    0    0   0   [1]     Nadam   0.914677    0.205629  0.923231   \n",
       "24   64   32    0    0   0   [1]   RMSprop   0.911114    0.211151  0.919730   \n",
       "7    32   16    0    0   0   [1]     Nadam   0.920240    0.193405  0.920480   \n",
       "11   64   16    0    0   0   [1]     Nadam   0.922865    0.191926  0.923981   \n",
       "15  128   16    0    0   0   [1]     Nadam   0.919740    0.190584  0.923731   \n",
       "29  128   32    0    0   0   [1]      Adam   0.920428    0.194369  0.916729   \n",
       "17   16   32    0    0   0   [1]      Adam   0.912677    0.216945  0.923731   \n",
       "21   32   32    0    0   0   [1]      Adam   0.916052    0.206061  0.920730   \n",
       "20   32   32    0    0   0   [1]   RMSprop   0.913802    0.214059  0.925731   \n",
       "33   16   64    0    0   0   [1]      Adam   0.902425    0.234574  0.921480   \n",
       "23   32   32    0    0   0   [1]     Nadam   0.923928    0.184304  0.921980   \n",
       "25   64   32    0    0   0   [1]      Adam   0.917865    0.199268  0.916229   \n",
       "3    16   16    0    0   0   [1]     Nadam   0.914739    0.208699  0.913728   \n",
       "32   16   64    0    0   0   [1]   RMSprop   0.893987    0.253523  0.919480   \n",
       "5    32   16    0    0   0   [1]      Adam   0.907801    0.223627  0.917229   \n",
       "16   16   32    0    0   0   [1]   RMSprop   0.903425    0.234117  0.916229   \n",
       "8    64   16    0    0   0   [1]   RMSprop   0.904676    0.230639  0.912978   \n",
       "13  128   16    0    0   0   [1]      Adam   0.912552    0.209694  0.912478   \n",
       "36   32   64    0    0   0   [1]   RMSprop   0.906113    0.225765  0.909977   \n",
       "9    64   16    0    0   0   [1]      Adam   0.909614    0.220658  0.916729   \n",
       "12  128   16    0    0   0   [1]   RMSprop   0.905801    0.230600  0.914479   \n",
       "4    32   16    0    0   0   [1]   RMSprop   0.902613    0.237722  0.912228   \n",
       "28  128   32    0    0   0   [1]   RMSprop   0.911426    0.211637  0.913228   \n",
       "1    16   16    0    0   0   [1]      Adam   0.902113    0.235470  0.912728   \n",
       "0    16   16    0    0   0   [1]   RMSprop   0.897862    0.249688  0.903476   \n",
       "22   32   32    0    0   0   [1]       SGD   0.811101    0.439903  0.846712   \n",
       "6    32   16    0    0   0   [1]       SGD   0.818477    0.424162  0.837959   \n",
       "18   16   32    0    0   0   [1]       SGD   0.819102    0.430787  0.842711   \n",
       "34   16   64    0    0   0   [1]       SGD   0.818415    0.442531  0.845711   \n",
       "26   64   32    0    0   0   [1]       SGD   0.815914    0.448350  0.844211   \n",
       "2    16   16    0    0   0   [1]       SGD   0.806538    0.448809  0.842461   \n",
       "14  128   16    0    0   0   [1]       SGD   0.814289    0.454584  0.837209   \n",
       "30  128   32    0    0   0   [1]       SGD   0.809226    0.447843  0.831208   \n",
       "10   64   16    0    0   0   [1]       SGD   0.802600    0.475585  0.837709   \n",
       "\n",
       "    val_loss  \n",
       "27  0.182697  \n",
       "31  0.188866  \n",
       "19  0.194389  \n",
       "35  0.196220  \n",
       "24  0.197624  \n",
       "7   0.198082  \n",
       "11  0.198908  \n",
       "15  0.199320  \n",
       "29  0.200601  \n",
       "17  0.200625  \n",
       "21  0.201580  \n",
       "20  0.201666  \n",
       "33  0.201901  \n",
       "23  0.202962  \n",
       "25  0.205678  \n",
       "3   0.208014  \n",
       "32  0.209666  \n",
       "5   0.211133  \n",
       "16  0.213399  \n",
       "8   0.215362  \n",
       "13  0.215649  \n",
       "36  0.218334  \n",
       "9   0.219749  \n",
       "12  0.220257  \n",
       "4   0.222930  \n",
       "28  0.223369  \n",
       "1   0.226381  \n",
       "0   0.235442  \n",
       "22  0.375535  \n",
       "6   0.377356  \n",
       "18  0.378661  \n",
       "34  0.380126  \n",
       "26  0.383301  \n",
       "2   0.385470  \n",
       "14  0.396841  \n",
       "30  0.401181  \n",
       "10  0.406585  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_LSTM_sort = embeddings_LSTM.sort_values(['val_loss'])\n",
    "embeddings_LSTM_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_LSTM(fl1=16, fl2=16, fl3=16, dl=16, optimizer= 'RMSprop', kl = 5, layer =1): \n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    x = Bidirectional(LSTM(units = fl1, return_sequences=True))(embedded_sequences)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dense(units=dl, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    preds = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.compile(loss= 'categorical_crossentropy',\n",
    "              optimizer= optimizer,\n",
    "              metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15998 samples, validate on 3999 samples\n",
      "Epoch 1/2\n",
      "15998/15998 [==============================] - 919s 57ms/step - loss: 0.2846 - acc: 0.8809 - val_loss: 0.2135 - val_acc: 0.9162\n",
      "Epoch 2/2\n",
      "15998/15998 [==============================] - 889s 56ms/step - loss: 0.1744 - acc: 0.9281 - val_loss: 0.1940 - val_acc: 0.9237\n",
      "17088/17088 [==============================] - 205s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "kwargs = dict(fl1=32, fl2= 0, fl3=0, kl=5, dl=64, optimizer= ''.join('Nadam'), layer=1)\n",
    "model = embedding_LSTM(**kwargs)\n",
    "model.fit(x_train, y_train, batch_size= 16, epochs=2, validation_data=(x_val, y_val))\n",
    "model1_test_y = model.predict(x_test, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15998 samples, validate on 3999 samples\n",
      "Epoch 1/2\n",
      "15998/15998 [==============================] - 884s 55ms/step - loss: 0.2822 - acc: 0.8769 - val_loss: 0.2185 - val_acc: 0.9110\n",
      "Epoch 2/2\n",
      "15998/15998 [==============================] - 876s 55ms/step - loss: 0.1773 - acc: 0.9273 - val_loss: 0.2021 - val_acc: 0.9162\n",
      "17088/17088 [==============================] - 195s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "kwargs = dict(fl1=32, fl2= 0, fl3=0, kl=5,dl=128, optimizer= ''.join('Nadam'), layer=1)\n",
    "model = embedding_LSTM(**kwargs)\n",
    "model.fit(x_train, y_train, batch_size= 16, epochs=2, validation_data=(x_val, y_val))\n",
    "model2_test_y = model.predict(x_test, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3rd model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15998 samples, validate on 3999 samples\n",
      "Epoch 1/2\n",
      "15998/15998 [==============================] - 922s 58ms/step - loss: 0.2972 - acc: 0.8745 - val_loss: 0.2527 - val_acc: 0.8945\n",
      "Epoch 2/2\n",
      "15998/15998 [==============================] - 910s 57ms/step - loss: 0.1867 - acc: 0.9236 - val_loss: 0.2268 - val_acc: 0.9052\n",
      "17088/17088 [==============================] - 197s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "kwargs = dict(fl1=32, fl2= 0, fl3=0, kl=5, dl=16, optimizer= ''.join('Nadam'), layer=1)\n",
    "model = embedding_LSTM(**kwargs)\n",
    "model.fit(x_train, y_train, batch_size= 16, epochs=2, validation_data=(x_val, y_val))\n",
    "model3_test_y = model.predict(x_test, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_y = 0.33*model1_test_y + 0.33*model2_test_y + 0.34*model3_test_y\n",
    "A = pred_test_y[:,0]\n",
    "B = pred_test_y[:,1]\n",
    "pred_array =[]\n",
    "\n",
    "for i in range(len(pred_test_y)):\n",
    "    if (A[i]>0.99):\n",
    "        pred_array.append(0)\n",
    "    else:\n",
    "        pred_array.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score on test set is 64.00%\n"
     ]
    }
   ],
   "source": [
    "predictions = pred_array\n",
    "actuals = labels_test_set.values\n",
    "true_pos= 0\n",
    "true_neg = 0\n",
    "false_pos = 0\n",
    "false_neg = 0\n",
    "for i in range (17088):\n",
    "    if ((predictions[i]==1) & (actuals[i]==1)):\n",
    "        true_pos = true_pos+1\n",
    "    elif((predictions[i]==0) & (actuals[i]==0)):\n",
    "        true_neg = true_neg+1\n",
    "    elif((predictions[i]==1) & (actuals[i]==0)):\n",
    "        false_pos = false_pos +1\n",
    "    elif((predictions[i]==0) & (actuals[i]==1)):\n",
    "        false_neg = false_neg+1\n",
    "prec=true_pos/(true_pos+false_pos)\n",
    "recall = true_pos/(true_pos+false_neg)\n",
    "accur=(true_pos+true_neg)/(true_pos+false_pos+ true_neg+ false_neg)\n",
    "F1=2*(prec*recall/(prec+recall))\n",
    "print('F1-score on test set is {0:.2f}%'.format(round(F1*100),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
